# dimens√µes de entrada das imagens a serem utilizadas na UNet 
IMG_HEIGHT = 448
IMG_WIDTH = 448
IMG_CHANNELS = 1


# arquitetura da UNet 
kw = dict(activation='relu', kernel_initializer='he_normal', padding='same')

inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))
#s = Lambda(lambda x: x / 255)(inputs)

#Contraction path
c1 = Conv2D(32, (3, 3), **kw)(inputs)
c1 = Dropout(0.1)(c1)
c1 = Conv2D(16, (3, 3), **kw)(c1)
p1 = MaxPooling2D((2, 2))(c1)

c2 = Conv2D(64, (3, 3), **kw)(p1)
c2 = Dropout(0.1)(c2)
c2 = Conv2D(32, (3, 3), **kw)(c2)
p2 = MaxPooling2D((2, 2))(c2)
 
c3 = Conv2D(128, (3, 3), **kw)(p2)
c3 = Dropout(0.2)(c3)
c3 = Conv2D(64, (3, 3), **kw)(c3)
p3 = MaxPooling2D((2, 2))(c3)
 
c4 = Conv2D(256, (3, 3), **kw)(p3)
c4 = Dropout(0.2)(c4)
c4 = Conv2D(128, (3, 3), **kw)(c4)
p4 = MaxPooling2D(pool_size=(2, 2))(c4)
 
c5 = Conv2D(512, (3, 3), **kw)(p4)
c5 = Dropout(0.3)(c5)
c5 = Conv2D(256, (3, 3), **kw)(c5)

kw_conv2transp = dict(strides=(2, 2), padding='same')
u6 = Conv2DTranspose(256, (2, 2), **kw_conv2transp)(c5)
u6 = concatenate([u6, c4])
c6 = Conv2D(256, (3, 3), **kw)(u6)
c6 = Dropout(0.2)(c6)
c6 = Conv2D(256, (3, 3), **kw)(c6)
 
u7 = Conv2DTranspose(64, (2, 2), **kw_conv2transp)(c6)
u7 = concatenate([u7, c3])
c7 = Conv2D(64, (3, 3), **kw)(u7)
c7 = Dropout(0.2)(c7)
c7 = Conv2D(64, (3, 3), **kw)(c7)
 
u8 = Conv2DTranspose(128, (2, 2), **kw_conv2transp)(c7)
u8 = concatenate([u8, c2])
c8 = Conv2D(128, (3, 3), **kw)(u8)
c8 = Dropout(0.1)(c8)
c8 = Conv2D(128, (3, 3), **kw)(c8)
 
u9 = Conv2DTranspose(64, (2, 2), **kw_conv2transp)(c8)
u9 = concatenate([u9, c1], axis=3)
c9 = Conv2D(64, (3, 3), **kw)(u9)
c9 = Dropout(0.1)(c9)
c9 = Conv2D(64, (3, 3), **kw)(c9)

outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)
 
model = Model(inputs=[inputs], outputs=[outputs])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()
